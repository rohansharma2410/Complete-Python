{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshalDharpure/Complte-Python-/blob/main/Complete_segmentation_and_Feature_Extraction_in_Lung_Cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Segmentaton Technique"
      ],
      "metadata": {
        "id": "bH8Z3n4onu7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('/content/input3.png')\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "cv2_imshow(gray)\n",
        "## Applying dilation for sure_bg detection\n",
        "ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
        "## Defining kernel for opening operation\n",
        "kernel = np.ones((3,3), np.uint8)\n",
        "opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "cv2_imshow(opening)\n",
        "## After opening, will perform dilation\n",
        "sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
        "## Sure background image\n",
        "cv2_imshow(sure_bg)"
      ],
      "metadata": {
        "id": "4Wa8ZJM6n0BA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
        "ret, sure_fg = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
        "sure_fg = np.uint8(sure_fg)\n"
      ],
      "metadata": {
        "id": "ueJiepzVqiir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unknown = np.subtract(sure_bg, sure_fg)\n",
        "cv2_imshow(unknown)"
      ],
      "metadata": {
        "id": "iE3nupvfpWYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Watershed Segmentation Algorithm"
      ],
      "metadata": {
        "id": "jYmTB3LAK85l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.feature import peak_local_max\n",
        "from skimage.segmentation import watershed\n",
        "from scipy import ndimage\n",
        "\n",
        "# Load the CT scan image\n",
        "image = cv2.imread('input3.png', 0)\n",
        "\n",
        "# Apply Gaussian Blur to the image to remove noise\n",
        "image = cv2.GaussianBlur(image, (5, 5), 0)\n",
        "\n",
        "# Obtain the internal marker by thresholding the image\n",
        "ret, thresh = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "# Perform morphological closing to fill the small holes in the image\n",
        "kernel = np.ones((3,3),np.uint8)\n",
        "closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations = 2)\n",
        "\n",
        "# Calculate the distance transform\n",
        "distance = ndimage.distance_transform_edt(closing)\n",
        "\n",
        "# Obtain the external marker by finding local maxima in the distance transform\n",
        "local_maxima = peak_local_max(distance, indices=False, footprint=np.ones((3, 3)), labels=closing)\n",
        "markers, n_markers = ndimage.label(local_maxima)\n",
        "\n",
        "# Perform marker-controlled watershed segmentation\n",
        "labels = watershed(-distance, markers, mask=closing)\n",
        "\n",
        "# Display the segmented image\n",
        "cv2_imshow(labels)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "XFKHC-porbxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global Thresholding Image Segmentation Technique"
      ],
      "metadata": {
        "id": "JvSSPwS1shoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load the lung CT scan image\n",
        "img = cv2.imread('input3.png', 0)\n",
        "\n",
        "# Apply a global threshold to the image\n",
        "ret, thresh = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "# Display the original and thresholded images\n",
        "cv2_imshow(img)\n",
        "cv2_imshow(thresh)\n",
        "\n",
        "# Wait for a key press\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "JOjmHce7sp73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Region & Edge based segmentation"
      ],
      "metadata": {
        "id": "TkM-pk_Eui0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.color import rgb2gray\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from scipy import ndimage\n",
        "from PIL import Image\n",
        "from sklearn.cluster import KMeans\n",
        "from skimage.filters import sobel\n",
        "import skimage\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "SUt5VPkaumoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image=Image.open('input3.png')\n",
        "image=image.resize((320,225))\n",
        "image=np.array(image)\n",
        "plt.imshow(image)"
      ],
      "metadata": {
        "id": "ty1varYFwCnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Region Based Segmentation of image with K=2 Folds"
      ],
      "metadata": {
        "id": "ABbgwyTw0rOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load the input image\n",
        "img = cv2.imread('input3.png')\n",
        "\n",
        "# Convert the image to grayscale\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Apply median filtering to remove noise\n",
        "gray = cv2.medianBlur(gray, 5)\n",
        "\n",
        "# Set the number of iterations for erosion and dilation\n",
        "iterations = 5\n",
        "\n",
        "# Initialize the mask\n",
        "mask = np.zeros_like(gray)\n",
        "\n",
        "# Get the width and height of the image\n",
        "width, height = gray.shape\n",
        "\n",
        "# Divide the image into K=2 folds\n",
        "for k in range(2):\n",
        "\n",
        "    # Set the ROI for the current fold\n",
        "    if k == 0:\n",
        "        roi = (0, 0, height // 2, width)\n",
        "    else:\n",
        "        roi = (height // 2, 0, height, width)\n",
        "\n",
        "    # Get the ROI of the image\n",
        "    roi_gray = gray[roi[0]:roi[2], roi[1]:roi[3]]\n",
        "\n",
        "    # Compute the threshold using Otsu's method\n",
        "    _, thresh = cv2.threshold(roi_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Perform erosion and dilation to remove small holes\n",
        "    for i in range(iterations):\n",
        "        thresh = cv2.erode(thresh, None, iterations=1)\n",
        "        thresh = cv2.dilate(thresh, None, iterations=1)\n",
        "\n",
        "    # Add the thresholded ROI to the mask\n",
        "    mask[roi[0]:roi[2], roi[1]:roi[3]] = thresh\n",
        "\n",
        "# Apply the mask to the input image\n",
        "segmented = cv2.bitwise_and(img, img, mask=mask)\n",
        "\n",
        "# Display the original and segmented images\n",
        "cv2_imshow(img)\n",
        "cv2_imshow(segmented)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "Lw_dzipQNkWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Region Based Segmentation of Image with K=5 Folds"
      ],
      "metadata": {
        "id": "lUr-t1PC00yT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr=gray.flatten()\n",
        "for i in range(len(arr)):\n",
        "    if arr[i]>=arr.mean():\n",
        "        arr[i]=4\n",
        "    elif arr[i]>=0.75:\n",
        "        arr[i]=3\n",
        "    elif arr[i]>0.5 :\n",
        "        arr[i]=2\n",
        "    elif arr[i]>0.25:\n",
        "        arr[i]=1\n",
        "    else:\n",
        "        arr[i]=0\n",
        "gray_segmented_2=arr.reshape(gray.shape[0],gray.shape[1])"
      ],
      "metadata": {
        "id": "pc7hApMV06wH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(18,8))\n",
        "plt.imshow(gray_segmented_2,cmap='pink')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GBK_-n000l_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Region-based method using the watershed transform"
      ],
      "metadata": {
        "id": "hz-e4oM11HpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imm=image[:,:,0]\n",
        "elevation_map = sobel(imm)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(18,8))\n",
        "ax.imshow(elevation_map, cmap='gray', interpolation='nearest')\n",
        "ax.axis('off')\n",
        "ax.set_title('elevation_map')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tZ9uI_4n1JaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(imm.flatten())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5h0AEyyRuarI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "markers = np.zeros_like(imm)\n",
        "markers[imm < 117] = 1\n",
        "markers[imm > 232] = 2\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8,4))\n",
        "ax.imshow(markers, cmap='Spectral', interpolation='nearest')\n",
        "ax.axis('off')\n",
        "ax.set_title('markers')"
      ],
      "metadata": {
        "id": "yai_fOSF1U5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Edge-Based Segmentation Technique"
      ],
      "metadata": {
        "id": "xrtugvwh17qt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_laplace = np.array([np.array([1, 1, 1]), np.array([1, -8, 1]), np.array([1, 1, 1])])\n",
        "\n",
        "out_l = ndimage.convolve(gray_segmented_2, kernel_laplace, mode='reflect')\n",
        "arr=[]\n",
        "for i in out_l.flatten():\n",
        "    if i == 0:\n",
        "        arr.append(0)\n",
        "    else:\n",
        "        arr.append(-100)\n",
        "arr=np.array(arr)\n",
        "arr=arr.reshape(out_l.shape[0],out_l.shape[1])\n",
        "plt.imshow(arr,cmap='gray', interpolation='nearest')"
      ],
      "metadata": {
        "id": "chRil0QD1_3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im=image/255\n",
        "pic=im.reshape(im.shape[0]*im.shape[1],im.shape[2])"
      ],
      "metadata": {
        "id": "GiUuqmfr1gar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(2, 3, figsize=(16, 8))\n",
        "count=1\n",
        "for i in range(2):\n",
        "    for j in range(3):\n",
        "\n",
        "        kmeans = KMeans(n_clusters=count+1, random_state=0).fit(pic)\n",
        "        pic_print = kmeans.cluster_centers_[kmeans.labels_]\n",
        "        clustered_pic=pic_print.reshape(im.shape[0],im.shape[1],im.shape[2])\n",
        "        count+=1\n",
        "        ax[i][j].set_title('Cluster '+str(count))\n",
        "        ax[i][j].imshow(clustered_pic)\n",
        "        ax[i][j].set_axis_off()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "adGOtwpK2Tme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Edge Based Detection"
      ],
      "metadata": {
        "id": "xhV5-DzKTjS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "# read image\n",
        "img = cv2.imread('input3.png', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# apply Gaussian blur to reduce noise\n",
        "img_blur = cv2.GaussianBlur(img, (3,3), 0)\n",
        "\n",
        "# apply Canny edge detector\n",
        "edges = cv2.Canny(img_blur, 50, 150)\n",
        "\n",
        "# perform morphological closing to connect broken edges\n",
        "kernel = np.ones((5,5),np.uint8)\n",
        "closing = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "# display results\n",
        "cv2_imshow(img)\n",
        "cv2_imshow(edges)\n",
        "cv2_imshow(closing)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "42h_iLN10xwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-means Clustering Algorithm"
      ],
      "metadata": {
        "id": "TlDGzhfRT2vd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from google.colab.patches import cv2_imshow\n",
        "# Load the input image\n",
        "image = cv2.imread('input3.png')\n",
        "\n",
        "# Reshape the image to a 2D array of pixels\n",
        "pixels = image.reshape((-1, 3))\n",
        "\n",
        "# Define the number of clusters\n",
        "n_clusters = 3\n",
        "\n",
        "# Apply K-means clustering\n",
        "kmeans = KMeans(n_clusters=n_clusters)\n",
        "kmeans.fit(pixels)\n",
        "labels = kmeans.predict(pixels)\n",
        "\n",
        "# Reshape the labels back to the original image shape\n",
        "labels = labels.reshape(image.shape[:2])\n",
        "\n",
        "# Create a mask for each label\n",
        "masks = [(labels == i).astype(np.uint8) for i in range(n_clusters)]\n",
        "\n",
        "# Display the output\n",
        "for i, mask in enumerate(masks):\n",
        "    cv2_imshow(mask * 255)\n",
        "\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "f3BJ511B85qD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}